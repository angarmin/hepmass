{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape:  (39983742, 29)\n",
      "test_shape:  (11943196, 29)\n"
     ]
    }
   ],
   "source": [
    "#Reading all txt\n",
    "data0 = pd.read_csv('/home/angela/Notebook/data/sin_norm/smttbar_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data1= pd.read_csv('/home/angela/Notebook/data/sin_norm/smttbar_aug24.txt', header = None, delimiter=\"\\t\") \n",
    "data0=pd.concat([data0, data1]) #Concat two txt\n",
    "label=pd.Series(np.repeat(0, data0.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(0, data0.shape[0])) #creating mass column\n",
    "data0.insert(0, 'label', label) #inserting label and mass\n",
    "data0.insert(28, 'mass', mass) \n",
    "\n",
    "data500 = pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m500_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data501= pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m500_aug17.txt', header = None, delimiter=\"\\t\")\n",
    "data500=pd.concat([data500, data501])\n",
    "label=pd.Series(np.repeat(1, data500.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(500, data500.shape[0])) #creating mass column\n",
    "data500.insert(0, 'label', label) #inserting label and mass\n",
    "data500.insert(28, 'mass', mass) \n",
    "\n",
    "data750 = pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m750_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data751= pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m750_aug17.txt', header = None, delimiter=\"\\t\")\n",
    "data750=pd.concat([data750, data751])\n",
    "label=pd.Series(np.repeat(1, data750.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(750, data750.shape[0])) #creating mass column\n",
    "data750.insert(0, 'label', label) #inserting label and mass\n",
    "data750.insert(28, 'mass', mass) \n",
    "\n",
    "data1000 = pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1000_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data1001= pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1000_aug17.txt', header = None, delimiter=\"\\t\")\n",
    "data1000=pd.concat([data1000, data1001])\n",
    "label=pd.Series(np.repeat(1, data1000.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(1000, data1000.shape[0])) #creating mass column\n",
    "data1000.insert(0, 'label', label) #inserting label and mass\n",
    "data1000.insert(28, 'mass', mass) \n",
    "\n",
    "data1250 = pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1250_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data1251= pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1250_aug24.txt', header = None, delimiter=\"\\t\")\n",
    "data1250=pd.concat([data1250, data1251])\n",
    "label=pd.Series(np.repeat(1, data1250.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(1250, data1250.shape[0])) #creating mass column\n",
    "data1250.insert(0, 'label', label) #inserting label and mass\n",
    "data1250.insert(28, 'mass', mass) \n",
    "\n",
    "data1500 = pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1500_aug4.txt', header = None, delimiter=\"\\t\")\n",
    "data1501= pd.read_csv('/home/angela/Notebook/data/sin_norm/xttbar_m1500_aug24.txt', header = None, delimiter=\"\\t\")\n",
    "data1500=pd.concat([data1500, data1501])\n",
    "label=pd.Series(np.repeat(1, data1500.shape[0])) #creating label column\n",
    "mass=pd.Series(np.repeat(1500, data1500.shape[0])) #creating mass column\n",
    "data1500.insert(0, 'label', label) #inserting label and mass\n",
    "data1500.insert(28, 'mass', mass) \n",
    "\n",
    "data=pd.concat([data0,data500,data750,data1000,data1250,data1500]) #concat all\n",
    "\n",
    "#With this Ive checked that there are not repeteated values: \n",
    "#duplicateRowsDF = data[data.duplicated()] #Checking duplicates\n",
    "#print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "#print(duplicateRowsDF)\n",
    "\n",
    "data = shuffle(data) #shufling\n",
    "\n",
    "#Renaming: \n",
    "\n",
    "columns=['label',   #LL:\n",
    "            'lep_pt', 'lep_eta','lep_phi',      #lepton\n",
    "            'met_miss', 'met_phi'  ,            #neutrino\n",
    "            'jets_no',                          #number of jets\n",
    "            'jet1_pt', 'jet1_eta','jet1_phi','jet1_btag',\n",
    "            'jet2_pt', 'jet2_eta','jet2_phi','jet2_btag',\n",
    "            'jet3_pt', 'jet3_eta','jet3_phi','jet3_btag',\n",
    "            'jet4_pt', 'jet4_eta','jet4_phi','jet4_btag',    #jets with more energy, HL:\n",
    "            'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_wwbb', #invariant mass\n",
    "            'mass']\n",
    "data.columns=columns\n",
    "\n",
    "\n",
    "\n",
    "#Making categorical variables are necessary:\n",
    "\n",
    "for col in ['jet1_btag', 'jet2_btag', 'jet3_btag','jet4_btag','label','jets_no','mass']:\n",
    "    data[col] = data[col].astype('category')\n",
    "    \n",
    "for col in ['jet1_btag', 'jet2_btag', 'jet3_btag','jet4_btag','jets_no']:\n",
    "    data[col] = data[col].astype('float')\n",
    "\n",
    "#data.shape: (51926938, 29) WE HAVE 52 millions of data? wtf..\n",
    "\n",
    "#spliting in train-test, this is a bit crappy but it works\n",
    "\n",
    "df, df_originaltest = data.iloc[:int(data.shape[0] * 0.77), :], data.iloc[int(data.shape[0] * 0.77):, :] \n",
    "\n",
    "#Saving: \n",
    "df.to_pickle(\"../data/sin_norm/trainpickle\")\n",
    "df_originaltest.to_pickle(\"../data/sin_norm/testpickle\")\n",
    "\n",
    "#Saving a simply version: \n",
    "dfsimple=df.sample(n=140000, random_state=1)\n",
    "df_originaltestsimple=df_originaltest.sample(n=70000, random_state=1)\n",
    "\n",
    "dfsimple.to_pickle(\"../data/sin_norm/trainsimplepickle\")\n",
    "df_originaltestsimple.to_pickle(\"../data/sin_norm/testsimplepickle\") \n",
    "\n",
    "print('train_shape: ', df.shape)\n",
    "print('test_shape: ', df_originaltest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
